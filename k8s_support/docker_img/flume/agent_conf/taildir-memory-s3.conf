# this agent will listen to port 88888, all the message receive from this port will be printed to the logger(std out)
# if local, use "nc localhost 88888" to start a terminal and type some message
# run flume agent with monitoring
# sh -c ./bin/flume-ng agent -n agent1 -f conf/test-agent.conf -Dflume.root.logger=INFO,console -Dflume.monitoring.type=http -Dflume.monitoring.port=44123
# ./flume-ng agent -n agent1 -f ../conf/test-agent.conf -Dflume.root.logger=DEBUG,LOGFILE>/tmp/flume-logs 2>&1 Dflume.monitoring.type=http -Dflume.monitoring.port=44123 &
# flume-ng agent -n agent1 -c ${FLUME_HOME}/conf -f ${FLUME_HOME}/conf/test-agent.conf -Dlog4j.configuration=${FLUME_HOME}/conf/log4j.properties -Dflume.monitoring.type=http -Dflume.monitoring.port=44123
# flume-ng agent -n agent1 -c ${FLUME_HOME}/conf -f ${FLUME_HOME}/conf/test-agent.conf -Dlog4j.configuration=log4j.properties -Dflume.monitoring.type=http -Dflume.monitoring.port=44123
# Name the components on this agent
agent1.sources = r1
agent1.sinks = k1
agent1.channels = c1

# Describe/configure the source
# agent1.sources.r1.type = TAILDIR
# agent1.sources.r1.bind = localhost
# agent1.sources.r1.port = 8888
agent1.sources.r1.type=TAILDIR
agent1.sources.r1.filegroups=f1
agent1.sources.r1.filegroups.f1=/tmp/log/app_log.*
# to store upload offset, can resume upload after failure
agent1.sources.r1.positionFile=/tmp/log/flume/taildir_position.json

# Describe the sink
agent1.sinks.k1.type = hdfs
agent1.sinks.k1.hdfs.path=s3a://pengfei/flume-test/logs/
# set to 0 to avoid file rolling, default value is 30, file 30 every 30 seconds
agent1.sinks.k1.hdfs.fileType=DataStream
agent1.sinks.k1.hdfs.filePrefix = events-
agent1.sinks.k1.hdfs.writeFormat = Text
agent1.sinks.k1.hdfs.batchSize = 100

# specify how many events a file should contain. If set to 0, it means never roll a file based on event number
agent1.sinks.k1.hdfs.rollCount = 0
# create a new slice file if the current file reaches 128MB
agent1.sinks.k1.hdfs.rollSize = 134217728
# specify how mach time flume waits to roll a file. the default value is 30 (seconds), if set to 0, never roll a file based on time
agent1.sinks.k1.hdfs.rollInterval = 0

# if your data has timestamp, you can specify path as rolling path
# a1.sinks.k1.hdfs.path = /flume/events/%y-%m-%d/%H%M/%S
# round the event timestamp
# a1.sinks.k1.hdfs.round = true
# round the timestamp of event every 10 minutes. As a result, event are grouped in folder every 10 mins
# a1.sinks.k1.hdfs.roundValue = 10
# a1.sinks.k1.hdfs.roundUnit = minute
# The above configuration with timestamp will round down the event timestamp to the last 10th minute. For example,
# an event with timestamp 11:54:34 AM, June 12, 2012 will cause the s3 path to become pengfei/flume-test/logs/events/2012-06-12/1150/00.



# Use a channel which buffers events in memory
agent1.channels.c1.type = memory
agent1.channels.c1.capacity = 1000
agent1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
agent1.sources.r1.channels = c1
agent1.sinks.k1.channel = c1