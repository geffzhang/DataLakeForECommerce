
# 1. create tables

## 1.1 External tables

For external tables, Hive does not manage the data of the External table.

We create an external table for external use as when we want to use the data outside the Hive.

External tables are stored outside the warehouse directory. They can access data stored in sources such as remote 
HDFS locations or Azure Storage Volumes.

Note here the location is the location of hive table in hdfs
```sql
create external table employee (employee_id int, birthday DATE, first_name STRING,family_name STRING,gender CHAR(1), work_day DATE) 
row format DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' 
stored as Parquet 
location '/hive_demo/tables/employees';

create external table salary (employee_id INT,salary INT,start_date DATE,end_date DATE) 
row format DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' 
stored as Parquet
location '/hive_demo/tables/salary';
```
## 1.2 Internal tables

For hive internal tables, Hive owns the data for the internal tables.

It is the default table in Hive. When the user creates a table in Hive without specifying it as external, 
then by default, an internal table gets created in a specific location in HDFS.


```sql
create table int_employee (employee_id int, birthday STRING, first_name STRING,family_name STRING,gender STRING) 
row format DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' 
stored as textfile
location '/hive_demo/tables/int_employee';

create table int_salary (employee_id INT,salary INT,start_date String,end_date String) 
row format DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' 
stored as textfile
location '/hive_demo/tables/int_salary';

```

Note, you can replace **textfile** by other format such as **Parquet**

## 1.3 External tables

```sql
create external table int_employee (employee_id int, birthday STRING, first_name STRING,family_name STRING,gender STRING) 
row format DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' 
stored as textfile
location '/hive_demo/tables/employee';

create external table int_salary (employee_id INT,salary INT,start_date DATE,end_date DATE) 
row format DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' 
stored as textfile
location '/hive_demo/tables/salary';
```
# 2. Load data
Employee.csv
```text
10001,1953-09-02,Georgi,Facello,M
10002,1964-06-02,Bezalel,Simmel,F
10003,1959-12-03,Parto,Bamford,M
10004,1954-05-01,Chirstian,Koblick,M
10005,1955-01-21,Kyoichi,Maliniak,M
10006,1953-04-20,Anneke,Preusig,F
10007,1957-05-23,Tzvetan,Zielinski,F
10008,1958-02-19,Saniya,Kalloufi,M
10009,1952-04-19,Sumant,Peac,F
10010,1963-06-01,Duangkaew,Piveteau,F

```

## 2.1 Load data into internal table


if the data is in the local file system, you can use below 
```sql

LOAD DATA LOCAL INPATH '/home/user/sample.txt' OVERWRITE INTO TABLE employee;
```

If the data is in hdfs, you can use below
```sql
LOAD DATA INPATH '/hive_demo/employees.csv' OVERWRITE INTO TABLE int_employee;

LOAD DATA INPATH '/hive_demo/salaries.csv' OVERWRITE INTO TABLE int_salary;


```

## 3. Table and source data compatibility

If we declare the table declared stored as Parquet, but the source data is text file (e.g. csv), you will receive the following error.

```text
Failed with exception java.io.IOException:java.lang.RuntimeException: hdfs://pengfei.org:9000/hive_demo/tables/salaries/salaries.csv i
s not a Parquet file. expected magic number at tail [80, 65, 82, 49] but found [49, 49, 39, 10]
```

Make sure the table declaration and data source format is compatible.


## 4. Some hive operation example

```sql
select e.first_name, e.family_name, avg(s.salary) as avg_salary from
    int_employee as e join int_salary as s on (e.employee_id == s.employee_id)
        group by e.first_name, e.family_name limit 5;

select e.gender, avg(s.salary) as avg_salary from
    employee as e join salary as s on (e.employee_id == s.employee_id)
        group by e.gender;

select e.first_name, e.family_name, avg(s.salary) as avg_salary from
    employee as e join salary as s on (e.employee_id == s.employee_id)
        group by e.first_name, e.family_name order by avg_salary limit 10;

select * from int_employee order by birthday asc limit 10;

select * from employee order by birthday asc limit 5;

select first_name, family_name, work_day from employee where work_day >= '1990-01-01' and work_day <= '1990-01-31'
```