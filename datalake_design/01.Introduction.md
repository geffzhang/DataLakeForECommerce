# 1.1 What is data lake?

A data lake is a central repository that stores data in its natural/raw format, usually object blobs or files. A data 
lake is usually a single store of data including raw copies of source system/business data, sensor data, social data 
etc., and transformed data used for tasks such as reporting, visualization, advanced analytics and machine learning. 

A data lake must be able to store structured data from relational databases (rows and columns), semi-structured data 
(CSV, logs, XML, JSON), unstructured data (emails, documents, PDFs) and binary data (images, audio, video).

A data lake can be established: 
- **on premises**: (within an organization's data centers)
- **in cloud**: public cloud (such as Amazon, Microsoft, or Google).

# 1.2 Why an enterprise need a data lake?

An enterprise has many departments, and they all produce data. For the CEO to understand what's going on inside his 
enterprise, he needs to 
- store these data in a central repository
- can analyse these data
- provide report on what's happened, why its happened.
- provide possible solutions on how to prevent bad things or increase good things to happen.

# 1.3 Common pitfalls of a data lake

To build a successful data lake, you must address non-functional requirements of a data lake
- security: Without it, no one will upload their data to the data lake 
- data governance/management: Without it, data will be not exploitable after upload. Hence data lake become a 
data swamp. Check this [paper](https://camps.aptaracorp.com/AuthorDashboard/dashboard.html?key=0&val=8b339ee9-d377-11eb-8d84-166a08e17233) for more details

A data lake is built for analyzing data, not for applying business transaction. As a result, normally it does not 
support the data modification after upload. When we do ETL, ELT, we create new data, but we don't change raw data. 
# 1.4 Overview of the data lake layers of an E-commerce  

## 1.4.1 Data sources layer 
In this project, we will build a data lake for an E-commerce enterprise. The first step is to identify the data source. 
Normally we can divide data sources into 3 categories:
- business transaction data: such as product description, inventory, user order, shipment, etc. Business Transaction data
  are the most import data for an e-commerce. They are often stored in a RDMS (e.g. oracle, postgres). 

- User behavior data: such as which product has been viewed (Visits), how much time the user spend on a specific section(Time On Site), 
  the number of unique visitor(Visitor), Page Views, Bounce Rate. These data are often stored in a log server in the 
  format of file or document based databased(e.g. mongo).
    
- web scraping data: such as the product prices of your competitors. This kind of data must be collected and used with 
  caution. You may encounter legal problems in some countries.
  
## 1.4.2 Data ingestion layer
In this project, we use flume to ingest user behavior data. Note it does exist many other framework/tool such as **canal**
For streaming data ingestion, we can also use spark streaming, Flink, combine with Kafka or rocketmq. 

# 1.5 Overview of the data warehouse
## 1.5.1数仓概念
- 什么是数仓：数据仓库是为企业所有决策制定过程，提供所有系统数据支持的战略集合。通过对数据仓库中数据的分析，可以帮助企业改进业务流程、控制成本、
  提高产品质量等。数据仓库并不是数据的最终目的地，而是为数据最终的目的地做好准备。这些准备包括对数据的清洗、转义、分类、重组、合并、拆分、统计等等

- 数仓的输入系统：埋点产生的用户行为数据、JavaEE 后台产生的业务数据、爬虫数据。

- 输出系统：报表系统、用户画像系统、风控系统、推荐系统、机器学习等

## 1.5.1.1 ODS（原始数据层）做了哪些事
1. 保持数据原貌，不做任何修改
2. 压缩采用 LZO，压缩比是 100g 数据压缩完 10g 左右。
3. 创建分区表

## 1.5.1.2 DWD（明细数据层）做了哪些事
1. 数据清洗 
   1. 空值去除 
   2. 过滤核心字段无意义的数据，比如订单表中订单 id 为 null，支付表中支付 id 为空
   3. 将用户行为宽表和业务表进行数据一致性处理

2. 清洗的手段: Sql、mr、spark、kettle、Python等等

3. 清洗掉多少数据算合理: 1 万条数据清洗掉 1 条。

4. 脱敏: 对手机号、身份证号等敏感数据脱敏

5. 维度退化: 对业务数据传过来的表进行维度退化和降维。（商品一级二级三级、省市县、年月日）

6. LZO压缩

7. 列式存储 parquet

## 1.5.1.3 DWS（服务数据层）做了哪些事
1. DWS 层有 3-5 张宽表（处理 100-200 个指标 70%以上的需求） 
   具体宽表名称：用户行为宽表，用户购买商品明细行为宽表，商品宽表，购物车宽表，物流宽表、登录注册、售后等。

2. 哪个宽表最宽？大概有多少个字段？
最宽的是用户行为宽表。大概有 60-100 个字段

3. 具体用户行为宽表字段名称
评论、打赏、收藏、关注–商品、关注–人、点赞、分享、好价爆料、文章发布、活跃、签到、补签卡、幸运屋、礼品、金币、电商点击、gmv

## 1.5.1.4 DWT（主题数据层）做了哪些事
1. 分析过的指标
日活、月活、周活、留存、留存率、新增（日、周、年）、转化率、流失、回流、七天内连续 3 天登录（点赞、收藏、评价、购买、加购、下单、活动）、连续 3 周（月）登录、GMV、复购率、复购率排行、点赞、评论、收藏、领优惠价人数、使用优惠价、沉默、值不值得买、退款人数、退款率 topn 热门商品

2. 留转 G 复活指标
（1）活跃
日活：100 万 ；月活：是日活的 2-3 倍 300 万
总注册的用户多少？1000 万-3000 万之间
（2）GMV
GMV：每天 10 万订单 （50 – 100 元） 500 万-1000 万
10%-20% 100 万-200 万
（3）复购率
某日常商品复购；（手纸、面膜、牙膏）10%-20%
电脑、显示器、手表 1%
（4）转化率
商品详情 =》 加购物车 =》下单 =》 支付
5%-10% 60-70% 90%-95%
（5）留存率
1/2/3、周留存、月留存
搞活动： 10-20%

## 1.5.1.5 ADS（应用数据层）做了哪些事
如何分析用户活跃？
在启动日志中统计不同设备 id 出现次数。

如何分析用户新增?
用活跃用户表 left join 用户新增表，用户新增表中 mid 为空的即为用户新增。

如何分析用户 1 天留存？
留存用户=前一天新增 join 今天活跃
用户留存率=留存用户/前一天新增

如何分析沉默用户？
(登录时间为 7 天前,且只出现过一次)
按照设备 id 对日活表分组，登录次数为 1，且是在一周前登录。

如何分析本周回流用户？
本周活跃 left join 本周新增 left join 上周活跃，且本周新增 id 和上周活跃 id 都为 null。

如何分析流失用户？
(登录时间为 7 天前)
按照设备 id 对日活表分组，且七天内没有登录过。

如何分析最近连续 3 周活跃用户数？
按照设备 id 对周活进行分组，统计次数大于 3 次。

如何分析最近七天内连续三天活跃用户数？
1）查询出最近 7 天的活跃用户，并对用户活跃日期进行排名
2）计算用户活跃日期及排名之间的差值
3）对同用户及差值分组，统计差值个数
4）将差值相同个数大于等于 3 的数据取出，然后去重，即为连续 3 天及以上活跃的用户
7 天连续收藏、点赞、购买、加购、付款、浏览、商品点击、退货
1 个月连续 7 天
连续两周

https://blog.csdn.net/wjt199866/article/details/115184169

### 宽表
含义：指字段比较多的数据库表。通常是指业务主体相关的指标、纬度、属性关联在一起的一张数据库表。宽表的设计广泛应用于数据挖掘模型训练前的数据准备，通过把相关字段放在同一张表中，可以大大提供数据挖掘模型训练过程中迭代计算的消息问题。
特点：宽表由于把不同的内容都放在同一张表，宽表已经不符合三范式的模型设计规范
坏处：数据有大量冗余
好处：查询性能的提高和便捷


# 1.5.2 The data warehouse architecture
- The stage layer is the data source.
  
- The ODS(Operation Data Store) layer stores raw data collected from various data sources of the STAGE layer. 
  
- The DWD (Data Warehouse Detail) layer, is responsible for cleaning and precipitating the data in ODS.  

- The DWB (Data Warehouse Basis) layer is a light summary. As a transition layer between the ODS layer and the DWS layer, 
  the DWB layer gently summarizes the data of the ODS layer and abstracts some common dimensions, such as time, region, 
  department, employee, etc. In these dimensions, we do some light data integration. For example, we can build a new 
  table that group complaints that a department suffers every day, or customer information summary of a certain month 
  of a certain month, etc., a slight summary can make data query more efficient. 
  
- The DWS (Data Warehouse Summary) layer, we build tables for each business topic that we are interested in.
  These table aggregate/join the data of the DWB layer based on certain topic. These tables are often stored as wide 
  tables. They can provide services for query, OLAP, data analysis, etc. of upper-layer applications. As we join and 
  aggregate once and persiste the result, this can increase the efficiency. 
  
- The DM (Date Market) layer, allows user to extract data of the DWS layer from the data warehouse directly to the user, 
  facing departments or teams in each system. 
  
- ADS (Application Data Store) layer Provides users with visual data query
  and analysis services based on DWS and DM based on the analysis business needs of users.

![Data warehouse architecture](https://raw.githubusercontent.com/pengfei99/DataLakeForECommerce/main/img/data_warehouse_architecture.PNG)

