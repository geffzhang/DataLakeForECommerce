# 2. Gathering data lake requirements

Normally the requirements are provided by the product manager of the project. He is responsible for collecting user 
story from all potential users(e.g. CEO that uses data lake to make decision. Departments that produce business data or
user behaviour data)

Note that we need to address not only the **functional requirements** (e.g. reporting, data viz), but also **non-functional
requirements** (e.g. scalability, availability, security, data governance, etc.)

Based on the requirements, 

## 2.1 An example of our data lake requirements

1. Collect and ingest business data, user behaviour data
2. Build multi-dimensional data model 
3. Analyze the data via different dimension/topic (e.g. products, locations, membership, etc) and produce report that
contains at least 100 indicators. For example, daily new/active membership subscriber, best sell products.
   
4. Provide an inter-active query system to allow exploratory data analysis.
5. Monitor data lake, be able to send alert(e.g. mail, sms) in case of error or exceptions.
6. Metadata management (Part of the data governance).
7. Data quality control
8. Key indicator monitoring. (e.g. When some indicators such as daily sales income change more than 30%, need to send alerts)
9. Security, such as authenticity, confidentiality(access control).
10. Scalability. For example, the data volume increase 100 TB each year, the data lake must be scalable to support this
11. Availability. For example, if some sever crash, can you allow some downtime?
12. Budge

## 2.2 Choose infrastructure  

Note requirement 10, 11 and 12 will influence how you choose your infrastructure(e.g. public cloud, premises server), 
and tools to implement the data lake. 

### Public cloud VMs VS Physical server.

A physical server with 20 core, 128GB memory, 8TB HDD 2TB SSD will cost about 5000 euros. It normally has a five-year warranty.
But it requires a room with  cooling system and a system administrator. 

In public cloud(e.g. aws, gcp), for a VM with the same cpu and memory will cost 6000 euros a year. 

If you are a small size company without a big budget, then use the public cloud is more efficient. If you are a mid or big size company then 
build a team and server room buy physical server is more efficient. 

### Estimate infrastructure size
We need to estimate the data volume/velocity that we will deal with, based on this estimation we will decide how many 
servers/vms which we need to buy.

For example:
- We have 1 million active user, each user produce 100 log message in average per day. So we will have 
1,000,000 * 100 =100,000,000 log message per day. 

- Suppose each message cost 1 kB, then we will have 100,000,000/1024/1024 = 100GB data per day.

- Suppose we don't want to add new server within 6 months, so we will have 100GB * 180 = 18TB

- Suppose we will have 3 backup. 18TB *3 = 54TB

- Suppose we want to have 30% buffer 54 / 0.7 = 77TB

So if one server has about 8TB disk, we will need 10 servers. Note if you want a more precise estimation, you need to 
consider all the intermediate data after data transformation, and the wide table that you produced for query and data viz.
You can also consider applying the data compression inside your data lake. 

## 2.3 Choose frameworks

Features that you need to consider when choosing a framework:
- Data volume/velocity (For example, 10 MB daily mysql is enough. 100GB daily mysql cannot handle it.)
- Business logic requirements
- Maturity and documentation of the framework
- Cost of the development/deployment
- Cost of the maintenance/upgrade

Suppose we have done the evaluation, and our data lake will use the following frameworks
- Data ingestion: Flume, Sqoop, Kafka, Logstash, DataX
- Data storage: MySql, HDFS, HBase, Redis, MongoDB
- Data transformation/analysis: Hive, Spark. (hive on spark)
- Data query: Presto, kylin
- Data viz: Echarts, Superset
- Workflow management: Airflow, Azkaban
- Platform monitoring: Prometheus, Zabbix
- Metadata management: Atlas
- Security/Access control: Kerberos, Ranger

![Data warehouse architecture](https://raw.githubusercontent.com/pengfei99/DataLakeForECommerce/main/img/data_flow_architecture.PNG)

Note, when you choose the version of your framework, don't choose the latest one. Because you may encounter many 
compatibility problems with other frameworks. Choose the latest stable before six month.