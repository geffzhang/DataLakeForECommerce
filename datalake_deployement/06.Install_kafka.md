# 6. Install a kafka cluster

## 6.0 Prerequisites

### 6.0.1 Install JDK
Kafka needs JDK or JRE to run. So the first step is to install jdk.

### 6.0.2 Install zookeeper
A critical dependency of Apache Kafka is Apache Zookeeper, which is a distributed configuration and 
synchronization service. Kafka uses ZooKeeper for:

- leadership election of Kafka Broker to elect Controller: The first arrived broker creates /kafka/controller 
  znode in zk. The other broker will fail because it already exists.
- partition replication leader/follower election
- discover new coming brokers
- stores basic metadata in Zookeeper such as information about topics(topic-partition pairs), brokers, consumer offsets (queue readers) and so on.
ETc.
  
Since all the critical information is stored in the Zookeeper, and it normally replicates this data across zk cluster, 
the failure of Kafka broker / Zookeeper does not affect the state of the Kafka cluster. Kafka will restore the state, 
once the Zookeeper restarts. These gives zero downtime for Kafka. The leader election between the Kafka broker is also 
done by using Zookeeper in the event of leader failure.
## 6.1 Creating a User for Kafka
```shell
# create a system user Kafka with a home dir
useradd -r kafka -m

# add Kafka to sudoer group
usermod -aG wheel kafka

# login as kafka
su -l kafka
```

## 6.2 Downloading and Extracting the Kafka Binaries
Download the kafka binary from http://kafka.apache.org/downloads.html

Note that Kafka uses Scala, and it's binary is compiled based on certain version of Scala. 
For example, kafka_2.11-1.0.0 means this Kafka version 1.0.0 is compiled based on scala 2.11; 
kafka_2.12-2.5.0 means this kafka of version 2.5.0 is compiled based on scala 2.12. 
So before you chose your kafka binary version, you need to check the scala version which runs on your server.

The latest stable verion is 2.8.0, and suppose our server runs scala 2.12. So we need to download the kafka_2.12-2.8.0.tgz

```shell

mkdir -p /opt/module/kafka

cd /opt/module/kafka

# Then download the binary 
wget https://miroir.univ-lorraine.fr/apache/kafka/2.8.0/kafka_2.12-2.8.0.tgz

# extract the binary
tar -xzvf kafka_2.12-2.8.0.tgz

# change the name
mv kafka_2.12-2.8.0 kafka-2.8.0

# check the result
[root@localhost kafka-2.8.0]# pwd
/opt/module/kafka-2.8.0
```
## 6.3 Setup env var
```shell
cd /etc/profile.d/

vim kafka.sh
# add following line
export KAFKA_HOME=/opt/module/kafka-2.8.0
export PATH=$PATH:$KAFKA_HOME/bin

# apply the config
source /etc/profile.d/kafka.sh
```
## 6.4 Configuring the Kafka Server
The main config file of a Kafka broker is on the **config/server.properties** file. The default config is 
enough to run a standalone Kafka broker as a test server. But we still want to highlight some key configuration attributes.

-【broker.id】 : Each broker has a unique id which is between 0~255. A good guideline is to set this value to something 
intrinsic to the host. For example, if your hostnames contain a unique number (such as host1.example.com , host2.example.com , etc.), 
that is a good choice for the broker.id value.

【log.dirs】 : Very important, becaue kafka write all transaction data under this folder，If you have multiple hard drive, 
you can set the multiple log dir, so data are split to multiple hard drive. This increase the throughput of the cluster.
If more than one path is specified(e.g. log.dirs=path1,path2), the broker will store partitions on them in 
a “least-used” fashion with one partition’s log segments stored within the same path. Note that the 
broker will place a new partition in the path that has the least number of partitions currently 
stored in it, not the least amount of disk space used in the following situations

【zookeeper.connect】 : This specifies which zk cluster to be used by kafka. The default configuration is localhost:2181.

【Listeners】 : This specifies which port the broker will listen to for the client request,The default port is 9092. 
It will get the value returned from ** java.net.InetAddress.getCanonicalHostName() if not configured**. 
The port number can be set to any available port by changing the port configuration parameter. Keep in mind that if a 
port lower than 1024 is chosen, Kafka must be started as root. Running Kafka as root is not a recommended configuration.

Below is an example of kafka configuration
```shell
# open the config file
cd /opt/module/kafka-2.8.0/config
vim server.properties

# Edit the server.properties file accordingly
# In dl1 the id is 1, in dl2 the id is 2, etc..
broker.id=1 (2,3 in other two machines)

#in a cluster environment with multiple zookeeper instances
zookeeper.connect=dl01.pengfei.org:2181,dl02.pengfei.org:2181,dl03.pengfei.org:2181

# set log dir path
log.dirs=fs_on_disk1/data/kafka-logs,fs_on_disk2/data/kafka-logs

# allow user to delete topic, disabled by default. 
delete.topic.enable=true

```

## 6.5 Start and stop the kafka cluster

```shell
# To start the server
# kafka-server-start.sh is the launch script. 
# - daemon option make kafka run as a daemon process
# we need to provide the path of the server.properties
sh /opt/module/kafka-2.8.0/bin/kafka-server-start.sh -daemon /opt/module/kafka-2.8.0/config/server.properties


# To stop the kafka process
sh /opt/module/kafka-2.8.0/bin/kafka-server-start.sh
```

Note, we need to run the above command on each node of the kafka cluster to start and stop the process. To make our 
life easier, we need a script to do it. Check the kafka_cluster_management.sh


## 6.6 Test the kafka cluster