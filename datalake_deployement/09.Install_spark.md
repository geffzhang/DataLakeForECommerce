# Deploy Spark


## 9.1 Deploy spark on standalone mode on a single server node

Download the spark binary that you have chosen(must be compatible with spark version in the hive3.1.2 build).
Then untar it and put it under /opt/module/
```shell
tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /opt/module/
mv /opt/module/spark-3.2.0-bin-hadoop3.2 /opt/module/spark
```
### 9.1.1 Start the master and slave process

```shell
# this stats a master process
./sbin/start-master.sh

# this starts a slave process and registered it to the master
./sbin/start-slave.sh spark://pengfei.org:7077
```

Now you can test it by creating a spark shell

```shell
spark-shell --master spark://pengfei.org:7077
```

Open the spark ui, you can see, you have **ONE spark driver and ONE spark executor** in Executors window. In the environment
window, you can see the url of the **spark.master is spark://pengfei.org:7077** 

## Monitor spark application with prometheus

https://databricks.com/session_na20/native-support-of-prometheus-monitoring-in-apache-spark-3-0

Spark 3.0 does better support on prometheus

To enable prometheus, in your spark submit or spark session, you need to add

```python
from pyspark.sql import SparkSession
import os

spark=SparkSession.builder \
             .master("k8s://https://kubernetes.default.svc:443") \
             .appName("SparkMonitoring") \
             .config("spark.kubernetes.container.image", "inseefrlab/jupyter-datascience:master") \
             .config("spark.kubernetes.authenticate.driver.serviceAccountName", os.environ['KUBERNETES_SERVICE_ACCOUNT']) \
             .config("spark.executor.instances", "4") \
             .config("spark.executor.memory","8g") \
             .config("spark.kubernetes.namespace", os.environ['KUBERNETES_NAMESPACE']) \
             .config("spark.ui.prometheus.enabled","true") \   
             .config("spark.kubernetes.driver.annotation.prometheus.io/scrape","true") \
             .config("spark.kubernetes.driver.annotation.prometheus.io/path","/metrics/executors/prometheus/") \
             .config("spark.kubernetes.driver.annotation.prometheus.io/port","4040") \
             .getOrCreate()
# The last four lines adds the prometheus monitoring support
```